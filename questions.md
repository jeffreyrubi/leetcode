# Questions
https://github.com/donnemartin/system-design-primer
https://youtu.be/LcJKxPXYudE?feature=shared


Learning Path
- Generative AI LLMs ÔºàProfessionalÔºâÔºö https://www.nvidia.com/en-us/learn/certification/generative-ai-llm-professional/
  - *Building RAG Agents with LLMs
  - *Adding New Knowledge to LLMs
  - *Deploying RAG Pipelines for Production at Scale
  - Model Parallelism: Building and Deploying Large Neural Networks

  - Optimizing CUDA Machine Learning Codes With Nsight Profiling Tools
- Agentic AI (Professional): https://www.nvidia.com/en-us/learn/certification/agentic-ai-professional/
  - *Building RAG Agents with LLMs
  - *Adding New Knowledge to LLMs
  - *Deploying RAG Pipelines for Production at Scale
  - Evaluating RAG and Semantic Search Systems
  - Building Agentic AI Applications with LLMs

Conference
- Ascend Conferences
- Nural information professional systems
- Afrotech


# Databricks Generative AI Associate

## Training Path
All current Databricks Academy ILT courses related to the Generative AI learner role,
specifically, Generative AI Engineering with Databricks.
‚óè Self-Paced (available in Databricks Academy): Generative AI Engineering with Databricks.
This self-paced course will soon be replaced with the following four modules.
‚óã Generative AI Solution Development (RAG)
‚óã Generative AI Application Development (Agents)
‚óã Generative AI Application Evaluation and Governance
‚óã Generative AI Application Deployment and Monitoring
‚óè Knowledge of current LLM‚Äôs and their capabilities
‚óè Knowledge of prompt engineering, prompt generation, and evaluation
‚óè Knowledge of current related online tools and services like LangChain, Hugging Face
Transformers, etc.
‚óè Working knowledge of Python and its libraries that support RAG application and LLM chain
development
‚óè Working knowledge of current APIs for data preparation, model chaining, etc.
‚óè Relevant Databricks Documentation resources


Behavior Mock Interview:
Oct 10, 15, 20, 31

Technical Mock Interview:
Oct 11, 15, 22, 29


Building GenAI solutions for enterprise with production quality. I do:
1) üßë‚Äçüíª prototype fast AI solutions to bring business values on table in the shortest timeframe.
2) üè≠ design scalable, multi-tenant LLM-powered solution that support 1000+ businesses.  
3) üîê secure AI Agents to comply a high data security standards.
4) üìä manage the model performance, agent traceability and context budgetsüí∞.

Practical industrial experience in Investment Banking üè¶, Supply Chain üöõ, Manufacturing üè≠.

‚ù§Ô∏è Contributes AI projects: Langchain, Google Agent Development Kit (ADK), Langfuse

If you're pondering scalable ML or resilient systems, let's connect.

| **Part of GPT**                     | **LeetCode Problem**                              | **Exact Location in nanoGPT** |
|-------------------------------------|--------------------------------------------------|--------------------------------|
| **Tokenization/Sequence Processing** | Longest Common Subsequence (#1143)               | https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py (data loading & binning) |
| **Sequence Alignment**              | Edit Distance (#72)                              | https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py (text processing) |
| **Attention Mechanism**             | Number of Islands (#200)                         | https://github.com/karpathy/nanoGPT/blob/master/model.py (causal self-attention) |
| **Dependency Resolution**           | Course Schedule II (#210)                        | https://github.com/karpathy/nanoGPT/blob/master/model.py (multi-head attention) |
| **Text Preprocessing**              | Longest Palindromic Substring (#5)               | https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py (string handling) |
| **Pattern Matching**                | Regular Expression Matching (#10)                | https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py (character-level matching) |
| **Embedding Manipulation**          | Two Sum (#1)                                     | https://github.com/karpathy/nanoGPT/blob/master/model.py (token embeddings) |
| **Matrix Operations for Attention** | Rotate Image (#48)                               | https://github.com/karpathy/nanoGPT/blob/master/model.py (attention matrix ops) |
| **Data Sorting for Efficiency**     | Merge Intervals (#56)                            | https://github.com/karpathy/nanoGPT/blob/master/train.py (batch sorting) |
| **Efficient Search in Data**        | Search in Rotated Sorted Array (#33)             | https://github.com/karpathy/nanoGPT/blob/master/train.py (data indexing) |
| **Low-Level Optimization**          | Single Number (#136)                             | https://github.com/karpathy/nanoGPT/blob/master/train.py (efficiency tweaks) |
| **Bitwise Operations for Efficiency**| Number of 1 Bits (#191)                        | https://github.com/karpathy/nanoGPT/blob/master/train.py (low-level ops) |
| **Sequence Windowing**              | Longest Substring Without Repeating Characters (#3) | https://github.com/karpathy/nanoGPT/blob/master/train.py (batching windows) |
| **Loss Optimization**               | Maximum Subarray (#53)                           | https://github.com/karpathy/nanoGPT/blob/master/train.py (loss computation)

